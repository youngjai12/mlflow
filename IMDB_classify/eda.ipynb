{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-22T22:47:13.010375Z",
     "start_time": "2024-01-22T22:47:13.007803Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 데이터 설명\n",
    "분류를 위해서는 긍정/부정 에 대한 label이 존재해야해서 이것들은 aclImdb/train/pos , aclImdb/train/neg 이렇게 구분지어져 있다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "84125825/84125825 [==============================] - 13s 0us/step\n"
     ]
    }
   ],
   "source": [
    "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "\n",
    "dataset = tf.keras.utils.get_file(\"data\", url,\n",
    "                                    untar=True, cache_dir='.',\n",
    "                                    cache_subdir='')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T22:36:27.479383Z",
     "start_time": "2024-01-22T22:35:56.134604Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "'./aclImdb'"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
    "dataset_dir"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T22:38:26.471035Z",
     "start_time": "2024-01-22T22:38:26.451801Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 데이터 생김새 살펴보기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rachel Griffiths writes and directs this award winning short film. A heartwarming story about coping with grief and cherishing the memory of those we've loved and lost. Although, only 15 minutes long, Griffiths manages to capture so much emotion and truth onto film in the short space of time. Bud Tingwell gives a touching performance as Will, a widower struggling to cope with his wife's death. Will is confronted by the harsh reality of loneliness and helplessness as he proceeds to take care of Ruth's pet cow, Tulip. The film displays the grief and responsibility one feels for those they have loved and lost. Good cinematography, great direction, and superbly acted. It will bring tears to all those who have lost a loved one, and survived.\n"
     ]
    }
   ],
   "source": [
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "\n",
    "sample_file = os.path.join(train_dir, 'pos/1181_9.txt')\n",
    "with open(sample_file) as f:\n",
    "  print(f.read())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T22:38:28.478565Z",
     "start_time": "2024-01-22T22:38:28.476058Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 데이터 분할작업"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75000 files belonging to 3 classes.\n",
      "Using 60000 files for training.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "raw_train_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    'aclImdb/train',\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=seed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T22:44:36.767023Z",
     "start_time": "2024-01-22T22:44:33.255990Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review b'There is this father-son conversation in the climax of \\'KALPURUSH\\'. I quote the English DVD-subtitle version. Shumonto tells his father: \"I may not have become someone, but when I see two people in love, I smile. And when I see someone eating alone, I cry.\" Ashvini, his father, replies wistfully: \"I wish I could\\'ve lived my life like you did.\" These 2 lines, perhaps, comprise the gist of this new film by Buddhadev Dasgupta - director of teeny-weeny gems like \\'Tahader Katha\\', \\'Bagh Bahadur\\', \\'Uttara\\' & \\'Mondo Meyer Upakhyan\\' - which took nearly 3 years to reach the cinemas in India.<br /><br />The film opens with a man called Ashvini following a younger man called Shumonto, who, we are told, is his son. It seems that the father is stalking - or haunting, rather - his son. As the film progresses and we meet Shumonto\\'s ambitious wife, Supriya, and his mother, Koyel, who seems to be tied up with something in her past, we realise that the son is, indeed, haunted by his father who was a somebody. He was a successful doctor and they had this beautiful family, but something - or someone - comes in and this happy husband-wife-child drift apart. This drifting apart is too hard for these three to endure, and the son, we see, is unable to lead even a proper relationship with his wife.<br /><br />I don\\'t know of too many father-son films from Bollywood or other Indian language films. I\\'ve seen only Ramesh Sippy\\'s \\'Shakti\\' & Feroze A. Khan\\'s \\'Gandhi, my father\\'. Both were the powerful types with dramatic, sad endings. I\\'ve also seen \\'Thevar Magan\\' & its Hindi remake \\'Virasat\\', but they were different. KALPURUSH is drama, but not the powerful type. It is, like other Dasgupta films, creatively- photographed, dream-like, poetic & soft. This keeps the viewer absolutely un-prepared for the surprise ending, for the film hardly feels like a father-son film. It starts like a husband-wife story, creates the tension, goes to become a mother-son film, and then explains why it is so, why the son is so, what was his relationship like with his father, what happens to the father, the mother, what the son\\'s wife does, and how the son carries on with his life.<br /><br />It would be unfair to dub KALPURUSH strictly for Buddhadev Dasgupta fans. However, I do suggest that the viewers acquaint themselves with Dasgupta\\'s films before going to see KALPURUSH. Dasgupta\\'s films are often accused of having a near-invisible storyline. KALPURUSH is no different. It starts, too, in a very un-Buddhadev Dasgupta-ish way. Instead of bare landscapes of Puruliya & Midnapore, one sees the trams of Calcutta in the opening credits. It helps, though, for it is like - What is this, urban Bengal? Soon after this, the film turns typical Dasgupta. The rural Bengal, this time, are the scenic outdoor locales of coastal Orissa.<br /><br />The actors are stupendous. Mithun Chakraborty is a legend. This is his second film with Dasgupta. He plays his age, suits the part, one just has to see him in this one. Rahul Bose is so silent one could feel the loss of his loser character. Sameera Reddy has looked good in just 3 films - \\'Musafir\\', \\'Migration\\' & \\'Kalpurush\\'. I haven\\'t seen \\'Ami, Yasin ar amar Madhubala\\' so I can\\'t comment on that. She better shift to the Bengali film industry. A mentor like Dasgupta would surely do her a lot good. Sudipta Chakraborty\\'s Other Woman role is short, but long enough to bring in that right amount of glamour, desire & heartbreak. Labony Sarkar is natural with a capital N.<br /><br />With the usual Buddhadev Dasgupta tropes in place, KALPURUSH is a visual treat. There are bare landscapes, dry leaves flying in the wind, haunting background score, mysterious folk artistes in even more mysterious costumes & masks, dilapidated, old buildings, and things rustic and antique. This time there is also the sea and an aeroplane flying right outside the open window. KALPURUSH is a film which needs to be seen.'\n",
      "Label 2\n",
      "Review b'The year 2005 saw no fewer than 3 filmed productions of H. G. Wells\\' great novel, \"War of the Worlds\". This is perhaps the least well-known and very probably the best of them. No other version of WotW has ever attempted not only to present the story very much as Wells wrote it, but also to create the atmosphere of the time in which it was supposed to take place: the last year of the 19th Century, 1900 \\xc2\\x85 using Wells\\' original setting, in and near Woking, England.<br /><br />IMDb seems unfriendly to what they regard as \"spoilers\". That might apply with some films, where the ending might actually be a surprise, but with regard to one of the most famous novels in the world, it seems positively silly. I have no sympathy for people who have neglected to read one of the seminal works in English literature, so let\\'s get right to the chase. The aliens are destroyed through catching an Earth disease, against which they have no immunity. If that\\'s a spoiler, so be it; after a book and 3 other films (including the 1953 classic), you ought to know how this ends.<br /><br />This film, which follows Wells\\' plot in the main, is also very cleverly presented \\xc2\\x96 in a way that might put many viewers off due to their ignorance of late 19th/early 20th Century photography. Although filmed in a widescreen aspect, the film goes to some lengths to give an impression of contemporaneity. The general coloration of skin and clothes display a sepia tint often found in old photographs (rather than black). Colors are often reminiscent of hand-tinting. At other times, colors are washed out. These variations are typical of early films, which didn\\'t use standardized celluloid stock and therefore presented a good many changes in print quality, even going from black/white to sepia/white to blue/white to reddish/white and so on \\xc2\\x96 as you\\'ll see on occasion here. The special effects are deliberately retrograde, of a sort seen even as late as the 1920s \\xc2\\x96 and yet the Martians and their machines are very much as Wells described them and have a more nearly realistic \"feel\". Some of effects are really awkward \\xc2\\x96 such as the destruction of Big Ben. The acting is often more in the style of that period than ours. Some aspects of Victorian dress may appear odd, particularly the use of pomade or brilliantine on head and facial hair.<br /><br />This film is the only one that follows with some closeness Wells\\' original narrative \\xc2\\x96 as has been noted. Viewers may find it informative to note plot details that appear here that are occasionally retained in other versions of the story. Wells\\' description of the Martians \\xc2\\x96 a giant head mounted on numerous tentacles \\xc2\\x96 is effectively portrayed. When the Martian machines appear, about an hour into the film, they too give a good impression of how Wells described them. Both Wells and this film do an excellent job of portraying the progress of the Martians from the limited perspective (primarily) of rural England \\xc2\\x96 plus a few scenes in London (involving the Narrator\\'s brother). The director is unable to resist showing the destruction of a major landmark (Big Ben), but at least doesn\\'t dwell unduly on the devastation of London.<br /><br />The victory of the Martians is hardly a surprise, despite the destruction by cannon of some of their machines. The Narrator, traveling about to seek escape, sees much of what Wells terms \"the rout of Mankind\". He encounters a curate endowed with the Victorian affliction of a much too precious and nervous personality. They eventually find themselves on the very edge of a Martian nest, where they discover an awful fact: the Martians are shown to be vampires who consume their prey alive in a very effective scene. Wells adds that after eating they set up \"a prolonged and cheerful hooting\". The Narrator finally is obliged to beat senseless the increasingly hysterical curate \\xc2\\x96 who revives just as the Martians drag him off to the larder (cheers from the gallery; British curates are so often utterly insufferable).<br /><br />This film lasts almost 3 hours, going through Wells\\' story in welcome detail. It\\'s about time the author got his due \\xc2\\x96 in a compelling presentation that builds in dramatic impact. A word about the acting: Don\\'t expect award-winning performances. They\\'re not bad, however, the actors are earnest and they grow on you. Most of them, however, have had very abbreviated film careers, often only in this film. The Narrator is played by hunky Anthony Piana, in his 2nd film. The Curate is John Kaufman \\xc2\\x96 also in his 2nd film as an actor but who has had more experience directing. The Brother (\"Henderson\") is played with some conviction by W. Bernard Bauman in his first film. The Artilleryman, the only other sizable part, is played by James Lathrop in his first film.<br /><br />This is overall a splendid film, portraying for the first time the War of the Worlds as Wells wrote it. Despite its slight defects, it is far and away better than any of its hyped-up competitors. If you want to see H. G. Wells\\' War of the Worlds \\xc2\\x96 and not some wholly distorted version of it \\xc2\\x96 see this film!'\n",
      "Label 1\n",
      "Review b\"This show is probably one of the worst shows I've seen on the network. I have begun to even avoid its commercials because I still am astonished how its been on TV so long. This show is probably the worst thing I've seen in a decade. When I say bad... I MEAN BAD. The things done are mostly scripted and very repetitive. All there is, is riots and people beating other people up. I just don't understand how this show was even thought about putting it on air, because its just so bad. It's completely ridiculous. Out of 5 stars *****, I don't think I would even give it a star.<br /><br />At all costs. Avoid this show.\"\n",
      "Label 2\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in raw_train_ds.take(1):\n",
    "  for i in range(3):\n",
    "    print(\"Review\", text_batch.numpy()[i])\n",
    "    print(\"Label\", label_batch.numpy()[i])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T22:45:03.386574Z",
     "start_time": "2024-01-22T22:45:03.336299Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0 corresponds to neg\n",
      "Label 1 corresponds to pos\n"
     ]
    }
   ],
   "source": [
    "print(\"Label 0 corresponds to\", raw_train_ds.class_names[0])\n",
    "print(\"Label 1 corresponds to\", raw_train_ds.class_names[1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T22:45:35.761770Z",
     "start_time": "2024-01-22T22:45:35.757241Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75000 files belonging to 3 classes.\n",
      "Using 15000 files for validation.\n"
     ]
    }
   ],
   "source": [
    "raw_val_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    'aclImdb/train',\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=seed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T22:45:50.654042Z",
     "start_time": "2024-01-22T22:45:47.503142Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "raw_test_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    'aclImdb/test',\n",
    "    batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T22:46:05.881276Z",
     "start_time": "2024-01-22T22:46:03.857968Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 텍스트 데이터를 전처리 하는 함수 및 layer\n",
    "- \\<br\\> 과 같은 태그 및 문장부호를 공백으로 대체\n",
    "-"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "  lowercase = tf.strings.lower(input_data)\n",
    "  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
    "  return tf.strings.regex_replace(stripped_html,\n",
    "                                  '[%s]' % re.escape(string.punctuation),\n",
    "                                  '')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T22:54:24.920626Z",
     "start_time": "2024-01-22T22:54:24.902208Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "\n",
    "max_features = 10000 # vocab의 사이즈의 크기\n",
    "sequence_length = 250\n",
    "\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=max_features,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T22:54:50.211375Z",
     "start_time": "2024-01-22T22:54:50.203760Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "<keras.src.layers.preprocessing.text_vectorization.TextVectorization at 0x1751045b0>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T22:47:29.361545Z",
     "start_time": "2024-01-22T22:47:29.356248Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "# Make a text-only dataset (without labels), then call adapt\n",
    "train_text = raw_train_ds.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(train_text)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T22:48:14.361761Z",
     "start_time": "2024-01-22T22:48:11.770322Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# vectorize 해서 전처리한 결과를 보여주는 함수\n",
    "\n",
    "def vectorize_text(text, label):\n",
    "  text = tf.expand_dims(text, -1)\n",
    "  return vectorize_layer(text), label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T22:48:52.833043Z",
     "start_time": "2024-01-22T22:48:52.831077Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 텍스트를 다 숫자로 치환한, vectorized 된 모습"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review tf.Tensor(b\"Okay I must say that before the revealing of the 'monster'. saying that he really didn't fit into that category, just some weird thing that had an annoying screech! And personally I think a granny could have ran away from that thing, but anyway. I actually was getting into this film, although having the main character a drunk and a heroine addict didn't come as an appeal. But such scenes as when she runs away from the train, and you can see the figure at the door was kind of creepy, also where the guard had just been killed and the 'monster' put his hand on the screen.<br /><br />But then disaster stuck form the moment the monster was revealed it just became your average horror, with limited thrills or scares. Slowly I became more bored, and wanted to shut the thing off. I like most people have said was rooting for the homeless people to make it, specially the guy, he gave me a few cheap laughs here and there. I think this film could have really been something special instead it became what every other horror nowadays are! Just boring and well not worth the money.<br /><br />if you are looking for a cheap scare here and there, or a mindless gore fest (which is limited, hardly any in fact) by all means give it a go, but for all you serious horror watchers look somewhere else, much better films out there.\", shape=(), dtype=string)\n",
      "Label neg\n",
      "Vectorized review (<tf.Tensor: shape=(1, 250), dtype=int64, numpy=\n",
      "array([[ 826,   11,  216,  134,   12,  159,    2, 3543,    5,    2,  895,\n",
      "         647,   12,   27,   63,  151, 1105,   77,   12, 2600,   40,   46,\n",
      "         970,  148,   12,   68,   33,  596,    1,    3, 1263,   11,  102,\n",
      "           4, 8186,   97,   25, 2134,  237,   35,   12,  148,   18,  573,\n",
      "          11,  157,   13,  371,   77,   10,   19,  263,  253,    2,  282,\n",
      "         106,    4, 1903,    3,    4, 2043, 6591,  151,  213,   14,   33,\n",
      "        1335,   18,  139,  131,   14,   50,   56, 1121,  237,   35,    2,\n",
      "        1237,    3,   22,   67,   66,    2,  842,   30,    2, 1199,   13,\n",
      "         239,    5, 1002,   78,  110,    2, 2896,   68,   40,   74,  509,\n",
      "           3,    2,  895,  269,   24,  555,   20,    2,  277,   18,   93,\n",
      "        1487, 1420,  815,    2,  560,    2,  895,   13, 1893,    9,   40,\n",
      "         873,  124,  836,  191,   15, 1697, 3502,   41, 2565, 1319,   11,\n",
      "         873,   51, 1023,    3,  458,    6, 2858,    2,  148,  123,   11,\n",
      "          38,   88,   80,   25,  290,   13, 5654,   16,    2, 4423,   80,\n",
      "           6,   94,    9, 5096,    2,  224,   27,  512,   69,    4,  166,\n",
      "         689,  907,  132,    3,   47,   11,  102,   10,   19,   97,   25,\n",
      "          63,   74,  136,  303,  295,    9,  873,   48,  167,   81,  191,\n",
      "        2886,   23,   40,  338,    3,   72,   21,  267,    2,  279,   45,\n",
      "          22,   23,  274,   16,    4,  689, 2286,  132,    3,   47,   41,\n",
      "           4, 2845,  610, 4453,   61,    7, 1697, 1003,  100,    8,  183,\n",
      "          32,   31,  777,  192,    9,    4,  137,   18,   16,   31,   22,\n",
      "         615,  191,    1,  161, 1238,  325,   71,  122,   91,   44,   47,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0]])>, <tf.Tensor: shape=(), dtype=int32, numpy=0>)\n"
     ]
    }
   ],
   "source": [
    "# retrieve a batch (of 32 reviews and labels) from the dataset\n",
    "text_batch, label_batch = next(iter(raw_train_ds))\n",
    "first_review, first_label = text_batch[0], label_batch[0]\n",
    "print(\"Review\", first_review)\n",
    "print(\"Label\", raw_train_ds.class_names[first_label])\n",
    "print(\"Vectorized review\", vectorize_text(first_review, first_label))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T22:48:59.848382Z",
     "start_time": "2024-01-22T22:48:59.816177Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1287 --->  charlie\n",
      " 313 --->  simply\n",
      "Vocabulary size: 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"1287 ---> \",vectorize_layer.get_vocabulary()[1287])\n",
    "print(\" 313 ---> \",vectorize_layer.get_vocabulary()[313])\n",
    "print('Vocabulary size: {}'.format(len(vectorize_layer.get_vocabulary())))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T22:52:01.321666Z",
     "start_time": "2024-01-22T22:52:01.292622Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 효율적으로 데이터 feeding 하기 위해 TF.Dataset API를 활용해서 준다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "train_ds = raw_train_ds.map(vectorize_text)\n",
    "val_ds = raw_val_ds.map(vectorize_text)\n",
    "test_ds = raw_test_ds.map(vectorize_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T22:55:39.490484Z",
     "start_time": "2024-01-22T22:55:39.402677Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "tensorflow.python.data.ops.batch_op._BatchDataset"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(raw_train_ds) ## dataset api 임."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T22:55:47.654114Z",
     "start_time": "2024-01-22T22:55:47.643059Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "tensorflow.python.data.ops.map_op._MapDataset"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_ds)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T22:56:03.527674Z",
     "start_time": "2024-01-22T22:56:03.522797Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
